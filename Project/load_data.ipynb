{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a62ca246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b406e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions loaded successfully with Python engine\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * Etape 1 : Load and inspect the dataset.\n",
    "\n",
    "\n",
    "# DÃ©finir le chemin des donnÃ©es\n",
    "path = \"../data_final_project/KuaiRec 2.0/data/\"\n",
    "\n",
    "# Charger les donnÃ©es\n",
    "small_matrix = pd.read_csv(path + \"small_matrix.csv\")\n",
    "big_matrix = pd.read_csv(path + \"big_matrix.csv\")\n",
    "item_categories = pd.read_csv(path + \"item_categories.csv\")\n",
    "item_features = pd.read_csv(path + \"item_daily_features.csv\")\n",
    "social_network = pd.read_csv(path + \"social_network.csv\")\n",
    "user_features = pd.read_csv(path + \"user_features.csv\")\n",
    "\n",
    "try:\n",
    "    # Method 1: Using Python engine instead of C engine\n",
    "    captions = pd.read_csv(path + \"kuairec_caption_category.csv\", engine='python')\n",
    "    print(\"Captions loaded successfully with Python engine\")\n",
    "except Exception as e:\n",
    "    print(f\"Method 1 failed: {e}\")\n",
    "    try:\n",
    "        # Method 2: Increase buffer size and skip bad lines\n",
    "        captions = pd.read_csv(path + \"kuairec_caption_category.csv\", \n",
    "                              engine='python', \n",
    "                              on_bad_lines='skip',\n",
    "                              encoding='utf-8')\n",
    "        print(\"Captions loaded successfully with skipping bad lines\")\n",
    "    except Exception as e:\n",
    "        print(f\"Method 2 failed: {e}\")\n",
    "        print(\"Unable to load captions file. Proceeding without it.\")\n",
    "        captions = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0444a3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AprÃ¨s suppression des valeurs manquantes, la matrice a 4494578 lignes\n",
      "Valeur max du 1% le plus bas: 0.10910294790311445\n",
      "Valeur min du 1% le plus haut: 56.26230695693068\n",
      "AprÃ¨s filtrage des valeurs extrÃªmes, la matrice a 4269399 lignes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * Etape 2 :  Traitement des valeurs manquantes et inconsistantes\n",
    "\n",
    "def clear_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Fonction pour nettoyer la matrice en traitant les valeurs manquantes et les valeurs extrÃªmes.\n",
    "    \n",
    "    Args:\n",
    "        matrix (DataFrame): La matrice d'interactions Ã  nettoyer\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: La matrice nettoyÃ©e\n",
    "    \"\"\"\n",
    "    # Traiter les valeurs manquantes\n",
    "    if matrix['timestamp'].isnull().sum() > 0:\n",
    "        # Supprimer les lignes avec timestamp manquant\n",
    "        matrix_cleaned = matrix.dropna(subset=['timestamp'])\n",
    "        print(f\"\\nAprÃ¨s suppression des valeurs manquantes, la matrice a {matrix_cleaned.shape[0]} lignes\")\n",
    "    else:\n",
    "        matrix_cleaned = matrix.copy()\n",
    "    \n",
    "    # Traitement des valeurs extrÃªmes dans watch_ratio\n",
    "\n",
    "    #q_low representes la valeur max du 1% le plus bas\n",
    "    q_low = matrix_cleaned['watch_ratio'].quantile(0.05) # ? jouer avec ce parametre\n",
    "    print(f\"Valeur max du 1% le plus bas: {q_low}\")\n",
    "    #q_high representes la valeur min du 1% le plus haut\n",
    "    q_high = matrix_cleaned['watch_ratio'].quantile(0.9999) # ? jouer avec ce parametre\n",
    "    print(f\"Valeur min du 1% le plus haut: {q_high}\")\n",
    "\n",
    "    # Filtrer les valeurs extrÃªmes\n",
    "    matrix_filtered = matrix_cleaned[(matrix_cleaned['watch_ratio'] >= q_low) & \n",
    "                                    (matrix_cleaned['watch_ratio'] <= q_high)]\n",
    "    print(f\"AprÃ¨s filtrage des valeurs extrÃªmes, la matrice a {matrix_filtered.shape[0]} lignes\")\n",
    "    \n",
    "    return matrix_filtered\n",
    "small_matrix_cleaned = clear_matrix(small_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee07aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour convertir la string en liste d'entiers\n",
    "def parse_item_categories_feat(cat_str):\n",
    "    \"\"\"\n",
    "    Convertit la reprÃ©sentation textuelle des catÃ©gories en liste d'entiers\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(cat_str, str):\n",
    "            # Supprimer les crochets et convertir en liste d'entiers\n",
    "            return [int(x) for x in cat_str.strip('[]').split(',') if x.strip()]\n",
    "        print(f\"Erreur de type pour la chaÃ®ne de catÃ©gories: {cat_str}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du parsing de la chaÃ®ne de catÃ©gories: {cat_str}, erreur: {e}\")\n",
    "        return []\n",
    "\n",
    "# Appliquer la fonction Ã  la colonne 'feat' en crÃ©ant une nouvelle colonne 'category_list'\n",
    "item_categories['category_list'] = item_categories['feat'].apply(parse_item_categories_feat)\n",
    "# CrÃ©er un dictionnaire de mapping video_id -> catÃ©gories pour un accÃ¨s efficace\n",
    "video_to_categories = dict(zip(item_categories['video_id'], item_categories['category_list']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6beb8539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemple d'interactions avec catÃ©gories:\n",
      "   user_id  video_id    categories  category_count\n",
      "0       14       148  [11, 28, 19]               3\n",
      "1       14       183          [28]               1\n",
      "2       14      3649           [9]               1\n",
      "3       14      5262          [25]               1\n",
      "4       14      8234           [6]               1\n",
      "\n",
      "Nombre de vidÃ©os sans catÃ©gorie: 0\n"
     ]
    }
   ],
   "source": [
    "def add_categories_to_interactions(interactions_df):\n",
    "    \"\"\"\n",
    "    Ajoute les catÃ©gories de vidÃ©os aux donnÃ©es d'interaction\n",
    "    \"\"\"\n",
    "    # CrÃ©er une colonne de catÃ©gories en utilisant le mapping\n",
    "    interactions_df['categories'] = interactions_df['video_id'].map(video_to_categories)\n",
    "    \n",
    "    # Remplacer les valeurs NaN par des listes vides\n",
    "    interactions_df['categories'] = interactions_df['categories'].fillna('').apply(lambda x: [] if x == '' else x)\n",
    "    \n",
    "    # Calculer le nombre de catÃ©gories par vidÃ©o\n",
    "    interactions_df['category_count'] = interactions_df['categories'].apply(len)\n",
    "    \n",
    "    return interactions_df\n",
    "\n",
    "# Fusionner les mÃ©tadonnÃ©es des catÃ©gories avec le jeu de donnÃ©es small_matrix nettoyÃ©\n",
    "small_matrix_with_categories = add_categories_to_interactions(small_matrix_cleaned)\n",
    "\n",
    "# VÃ©rifier la fusion des donnÃ©es\n",
    "print(\"\\nExemple d'interactions avec catÃ©gories:\")\n",
    "print(small_matrix_with_categories[['user_id', 'video_id', 'categories', 'category_count']].head())\n",
    "print(f\"\\nNombre de vidÃ©os sans catÃ©gorie: {sum(small_matrix_with_categories['category_count'] == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8156ec56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemple d'interactions avec captions:\n",
      "   user_id  video_id    categories  \\\n",
      "0       14       148  [11, 28, 19]   \n",
      "1       14       183          [28]   \n",
      "2       14      3649           [9]   \n",
      "3       14      5262          [25]   \n",
      "4       14      8234           [6]   \n",
      "\n",
      "                                             caption  \n",
      "0  ç¾60å²å¥¶å¥¶ä¸21å°‘å¹´ä¸€è§é’Ÿæƒ…ï¼Œå…´å¥‹åˆ†äº«åˆæ¬¡ä½“éªŒï¼Œç§°ï¼šå‡åäº†æ„Ÿæƒ…ï¼ @æ¨å¹¿å°åŠ©æ‰‹(O4030...  \n",
      "1          åˆè‚¥é«˜é“å—ç«™ï¼Œä»–å¸¦äº†ç“¶å¼€è¿‡å°çš„èŒ…å°è¢«æ‹¦ä¸‹ï¼Œé…’å€¼4000å…ƒä»–èˆä¸å¾—æ‰”ï¼Œå°±ä¸€é¥®è€Œå°½ã€‚   \n",
      "2                     ç¾å¥³è£¤å…œä¸Šæ’â€œèœåˆ€â€å“åæ—äºº   å“¦è±ï¼Œæ‹”å‡ºæ¥æ‰å‘ç°æ˜¯æ‰‹æœºå£³  \n",
      "3    ç”Ÿäº†ä¸ªæ´‹å¨ƒå¨ƒï¼Œå©†å©†éè¦å‘å‡ºæ¥ç»™å¤§å®¶çœ‹çœ‹ï¼Œçœ‹çœ‹æœ‰æ²¡æœ‰äººç‚¹èµï¼Œä¸€åˆ†é’Ÿå‚¬æˆ‘çœ‹ä¸€ä¸‹ï¼Œä¸€åˆ†é’Ÿå‚¬æˆ‘çœ‹ä¸€ä¸‹ğŸ˜‚  \n",
      "4  #éƒåŠ­æ–‡ å°æ—¶å€™ç«éå…¨å›½ï¼Œè·Ÿé‡Šå°é¾™ä¸€èµ·æˆä¸ºä¸€ä»£äººæœ€å–œçˆ±çš„ç«¥æ˜Ÿï¼Œé•¿å¤§åå´æ²¡èƒ½å¤§ç«ï¼Œä½ è¿˜è®°å¾—é‚£ä¸ª...  \n"
     ]
    }
   ],
   "source": [
    "# Solution alternative - nettoyer puis convertir en entiers si possible\n",
    "if captions is not None:\n",
    "    try:\n",
    "        # Fonction pour extraire seulement les chiffres\n",
    "        def extract_digits(value):\n",
    "            import re\n",
    "            digits = re.findall(r'\\d+', str(value))\n",
    "            return int(digits[0]) if digits else None\n",
    "        \n",
    "        # Appliquer la fonction\n",
    "        captions['video_id_int'] = captions['video_id'].apply(extract_digits)\n",
    "        \n",
    "        # Filtrer les lignes oÃ¹ la conversion a fonctionnÃ©\n",
    "        captions_valid = captions.dropna(subset=['video_id_int'])\n",
    "        \n",
    "        # CrÃ©er le dictionnaire avec les ID numÃ©riques\n",
    "        video_captions = dict(zip(captions_valid['video_id_int'], captions_valid['caption']))\n",
    "        \n",
    "        # Ajouter le texte des captions\n",
    "        small_matrix_with_categories['caption'] = small_matrix_with_categories['video_id'].map(video_captions)\n",
    "\n",
    "        print(\"\\nExemple d'interactions avec captions:\")\n",
    "        print(small_matrix_with_categories[['user_id', 'video_id', 'categories', 'caption']].head())\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'ajout des captions: {e}\")\n",
    "        print(\"Poursuite du traitement sans les donnÃ©es de captions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accda7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemple d'interactions avec mÃ©tadonnÃ©es agrÃ©gÃ©es:\n",
      "   user_id  video_id    categories  total_likes  avg_daily_likes  \\\n",
      "0       14       148  [11, 28, 19]        31199       495.222222   \n",
      "1       14       183          [28]       210670      3343.968254   \n",
      "2       14      3649           [9]       279456      4435.809524   \n",
      "3       14      5262          [25]      1363469     21642.365079   \n",
      "4       14      8234           [6]        87997      1396.777778   \n",
      "\n",
      "   total_comments  avg_daily_comments  \n",
      "0            4574           72.603175  \n",
      "1            5684           90.222222  \n",
      "2            5900           93.650794  \n",
      "3           29188          463.301587  \n",
      "4            4328           68.698413  \n"
     ]
    }
   ],
   "source": [
    "# VÃ©rifier si item_features est disponible\n",
    "if 'item_features' in locals() and not item_features.empty:\n",
    "    # Convertir date en datetime si nÃ©cessaire\n",
    "    if not pd.api.types.is_datetime64_any_dtype(item_features['date']):\n",
    "        item_features['date'] = pd.to_datetime(item_features['date'], format='%Y%m%d', errors='coerce')\n",
    "    \n",
    "    # SÃ©lectionner les colonnes d'intÃ©rÃªt\n",
    "    selected_features = ['video_id', 'date', 'play_progress', \n",
    "                         'like_cnt', 'comment_cnt', 'share_cnt']\n",
    "    \n",
    "    # CrÃ©er des agrÃ©gations pertinentes pour des compteurs quotidiens\n",
    "    video_features_agg = item_features[selected_features].groupby('video_id').agg({\n",
    "        'date': 'max',                    # Date la plus rÃ©cente pour rÃ©fÃ©rence\n",
    "        'play_progress': 'mean',          # Progression moyenne sur toute la pÃ©riode\n",
    "        'like_cnt': 'sum',                # Total des likes sur toute la pÃ©riode\n",
    "        'comment_cnt': 'sum',             # Total des commentaires sur toute la pÃ©riode\n",
    "        'share_cnt': 'sum'                # Total des partages sur toute la pÃ©riode\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculer le nombre de jours avec des donnÃ©es pour chaque vidÃ©o\n",
    "    days_per_video = item_features.groupby('video_id')['date'].nunique()\n",
    "    video_features_agg['days_tracked'] = video_features_agg['video_id'].map(days_per_video)\n",
    "    \n",
    "    # Calculer les moyennes quotidiennes\n",
    "    video_features_agg['avg_daily_likes'] = video_features_agg['like_cnt'] / video_features_agg['days_tracked']\n",
    "    video_features_agg['avg_daily_comments'] = video_features_agg['comment_cnt'] / video_features_agg['days_tracked']\n",
    "    video_features_agg['avg_daily_shares'] = video_features_agg['share_cnt'] / video_features_agg['days_tracked']\n",
    "    \n",
    "    # Renommer les colonnes pour reflÃ©ter l'agrÃ©gation\n",
    "    video_features_agg = video_features_agg.rename(columns={\n",
    "        'play_progress': 'avg_play_progress',\n",
    "        'like_cnt': 'total_likes',\n",
    "        'comment_cnt': 'total_comments',\n",
    "        'share_cnt': 'total_shares'\n",
    "    })\n",
    "    \n",
    "    # Fusionner avec notre dataset\n",
    "    small_matrix_with_metadata = pd.merge(\n",
    "        small_matrix_with_categories,\n",
    "        video_features_agg,\n",
    "        on='video_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_features')\n",
    "    )\n",
    "    \n",
    "    # Afficher un exemple du rÃ©sultat\n",
    "    print(\"\\nExemple d'interactions avec mÃ©tadonnÃ©es agrÃ©gÃ©es:\")\n",
    "    print(small_matrix_with_metadata[['user_id', 'video_id', 'categories', \n",
    "                                     'total_likes', 'avg_daily_likes', \n",
    "                                     'total_comments', 'avg_daily_comments']].head())\n",
    "else:\n",
    "    small_matrix_with_metadata = small_matrix_with_categories\n",
    "# suppression de la colonne 'date' et 'timestamp' car elles ne sont plus nÃ©cessaires\n",
    "small_matrix_with_metadata.drop(columns=['date', 'timestamp'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8800dcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensions finales du dataset fusionnÃ©: (4269399, 18)\n",
      "Nombre de colonnes aprÃ¨s fusion: 18\n",
      "Colonnes disponibles aprÃ¨s fusion:\n",
      "['user_id', 'video_id', 'play_duration', 'video_duration', 'time', 'watch_ratio', 'categories', 'category_count', 'caption', 'date_features', 'avg_play_progress', 'total_likes', 'total_comments', 'total_shares', 'days_tracked', 'avg_daily_likes', 'avg_daily_comments', 'avg_daily_shares']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * RÃ©capitulatif des donnÃ©es fusionnÃ©es\n",
    "print(f\"\\nDimensions finales du dataset fusionnÃ©: {small_matrix_with_metadata.shape}\")\n",
    "print(f\"Nombre de colonnes aprÃ¨s fusion: {len(small_matrix_with_metadata.columns)}\")\n",
    "print(\"Colonnes disponibles aprÃ¨s fusion:\")\n",
    "print(small_matrix_with_metadata.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c15939c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id  video_id  play_duration  video_duration  \\\n",
      "0             14       148           4381            6067   \n",
      "1             14       183          11635            6100   \n",
      "2             14      3649          22422           10867   \n",
      "3             14      5262           4479            7908   \n",
      "4             14      8234           4602           11000   \n",
      "...          ...       ...            ...             ...   \n",
      "4269394     7162      9177           5315           37205   \n",
      "4269395     7162      4987          10085            8167   \n",
      "4269396     7162      7988          50523           49319   \n",
      "4269397     7162      6533           2190            8000   \n",
      "4269398     7162      6523          11909            7255   \n",
      "\n",
      "                            time  watch_ratio    categories  category_count  \\\n",
      "0        2020-07-05 05:27:48.378     0.722103  [11, 28, 19]               3   \n",
      "1        2020-07-05 05:28:00.057     1.907377          [28]               1   \n",
      "2        2020-07-05 05:29:09.479     2.063311           [9]               1   \n",
      "3        2020-07-05 05:30:43.285     0.566388          [25]               1   \n",
      "4        2020-07-05 05:35:43.459     0.418364           [6]               1   \n",
      "...                          ...          ...           ...             ...   \n",
      "4269394  2020-09-01 20:06:35.984     0.142857          [16]               1   \n",
      "4269395  2020-09-02 14:44:51.342     1.234848          [28]               1   \n",
      "4269396  2020-09-03 08:45:01.474     1.024412          [16]               1   \n",
      "4269397  2020-09-04 22:56:32.021     0.273750          [28]               1   \n",
      "4269398  2020-09-05 00:32:09.154     1.641489      [25, 28]               2   \n",
      "\n",
      "                                                   caption date_features  \\\n",
      "0        ç¾60å²å¥¶å¥¶ä¸21å°‘å¹´ä¸€è§é’Ÿæƒ…ï¼Œå…´å¥‹åˆ†äº«åˆæ¬¡ä½“éªŒï¼Œç§°ï¼šå‡åäº†æ„Ÿæƒ…ï¼ @æ¨å¹¿å°åŠ©æ‰‹(O4030...    2020-09-05   \n",
      "1                åˆè‚¥é«˜é“å—ç«™ï¼Œä»–å¸¦äº†ç“¶å¼€è¿‡å°çš„èŒ…å°è¢«æ‹¦ä¸‹ï¼Œé…’å€¼4000å…ƒä»–èˆä¸å¾—æ‰”ï¼Œå°±ä¸€é¥®è€Œå°½ã€‚     2020-09-05   \n",
      "2                           ç¾å¥³è£¤å…œä¸Šæ’â€œèœåˆ€â€å“åæ—äºº   å“¦è±ï¼Œæ‹”å‡ºæ¥æ‰å‘ç°æ˜¯æ‰‹æœºå£³    2020-09-05   \n",
      "3          ç”Ÿäº†ä¸ªæ´‹å¨ƒå¨ƒï¼Œå©†å©†éè¦å‘å‡ºæ¥ç»™å¤§å®¶çœ‹çœ‹ï¼Œçœ‹çœ‹æœ‰æ²¡æœ‰äººç‚¹èµï¼Œä¸€åˆ†é’Ÿå‚¬æˆ‘çœ‹ä¸€ä¸‹ï¼Œä¸€åˆ†é’Ÿå‚¬æˆ‘çœ‹ä¸€ä¸‹ğŸ˜‚    2020-09-05   \n",
      "4        #éƒåŠ­æ–‡ å°æ—¶å€™ç«éå…¨å›½ï¼Œè·Ÿé‡Šå°é¾™ä¸€èµ·æˆä¸ºä¸€ä»£äººæœ€å–œçˆ±çš„ç«¥æ˜Ÿï¼Œé•¿å¤§åå´æ²¡èƒ½å¤§ç«ï¼Œä½ è¿˜è®°å¾—é‚£ä¸ª...    2020-09-05   \n",
      "...                                                    ...           ...   \n",
      "4269394                        æ•™ä½ ä¸€ä¸ªå°æ–¹æ³•ï¼Œ#ç¾ç™½Â  åˆ#å»çš±Â #å¥åº·ç§‘æ™®åœ¨å¿«æ‰‹Â     2020-09-05   \n",
      "4269395           è¾½å®å¤§é‡ç‰¹è­¦çªè¢­ä¸€è¯åº—ï¼Œå¤šäººè’™å¤´å¥—è¢«æŠ¼ï¼ç›®å‡»è€…ï¼šè¯¥è¯åº—å¼€ä¸šæ‰å‡ ä¸ªæœˆï¼Œçœ‹èµ·æ¥å¾ˆæ™®é€š    2020-09-05   \n",
      "4269396                è‚ä¸å¥½çš„5å¤§è¡¨ç°#ä¸­åŒ»å…»ç”Ÿ #å…»ç”Ÿ #å¥åº·å…»ç”Ÿ #ä¸­åŒ» #ä¸­åŒ»Â·ä¸­è¯     2020-09-05   \n",
      "4269397                                 å¿ƒç–¼ï¼ä¸¤å²å¤±æ˜ç™Œç—‡å®å®èˆ€ä¸åˆ°é¥­è¢«æ€¥å“­    2020-09-05   \n",
      "4269398                                     è¿™å¨ƒçŠ¶æ€æœ‰ç‚¹è¿· #å®¶æœ‰èŒå®     2020-09-05   \n",
      "\n",
      "         avg_play_progress  total_likes  total_comments  total_shares  \\\n",
      "0                 0.710828        31199            4574           577   \n",
      "1                 0.484098       210670            5684          1496   \n",
      "2                 0.681001       279456            5900          8383   \n",
      "3                 0.654183      1363469           29188          8583   \n",
      "4                 0.490624        87997            4328           181   \n",
      "...                    ...          ...             ...           ...   \n",
      "4269394           0.408722       600659            8454        307610   \n",
      "4269395           0.745295       321362            9760          3328   \n",
      "4269396           0.308004       180663            1473        118171   \n",
      "4269397           0.761755       683737           56849          3116   \n",
      "4269398           0.761855       349553           11081         14240   \n",
      "\n",
      "         days_tracked  avg_daily_likes  avg_daily_comments  avg_daily_shares  \n",
      "0                  63       495.222222           72.603175          9.158730  \n",
      "1                  63      3343.968254           90.222222         23.746032  \n",
      "2                  63      4435.809524           93.650794        133.063492  \n",
      "3                  63     21642.365079          463.301587        136.238095  \n",
      "4                  63      1396.777778           68.698413          2.873016  \n",
      "...               ...              ...                 ...               ...  \n",
      "4269394            13     46204.538462          650.307692      23662.307692  \n",
      "4269395             5     64272.400000         1952.000000        665.600000  \n",
      "4269396             4     45165.750000          368.250000      29542.750000  \n",
      "4269397             4    170934.250000        14212.250000        779.000000  \n",
      "4269398             4     87388.250000         2770.250000       3560.000000  \n",
      "\n",
      "[4269399 rows x 18 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['small_matrix_with_metadata.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(small_matrix_with_metadata)\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Sauvegarde\n",
    "joblib.dump(small_matrix_with_metadata, 'small_matrix_with_metadata.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recosys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
