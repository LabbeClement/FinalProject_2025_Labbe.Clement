{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a62ca246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2b406e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions loaded successfully with Python engine\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * Etape 1 : Load and inspect the dataset.\n",
    "\n",
    "\n",
    "# Définir le chemin des données\n",
    "path = \"../data_final_project/KuaiRec 2.0/data/\"\n",
    "\n",
    "# Charger les données\n",
    "small_matrix = pd.read_csv(path + \"small_matrix.csv\")\n",
    "big_matrix = pd.read_csv(path + \"big_matrix.csv\")\n",
    "item_categories = pd.read_csv(path + \"item_categories.csv\")\n",
    "item_features = pd.read_csv(path + \"item_daily_features.csv\")\n",
    "social_network = pd.read_csv(path + \"social_network.csv\")\n",
    "user_features = pd.read_csv(path + \"user_features.csv\")\n",
    "\n",
    "try:\n",
    "    # Method 1: Using Python engine instead of C engine\n",
    "    captions = pd.read_csv(path + \"kuairec_caption_category.csv\", engine='python')\n",
    "    print(\"Captions loaded successfully with Python engine\")\n",
    "except Exception as e:\n",
    "    print(f\"Method 1 failed: {e}\")\n",
    "    try:\n",
    "        # Method 2: Increase buffer size and skip bad lines\n",
    "        captions = pd.read_csv(path + \"kuairec_caption_category.csv\", \n",
    "                              engine='python', \n",
    "                              on_bad_lines='skip',\n",
    "                              encoding='utf-8')\n",
    "        print(\"Captions loaded successfully with skipping bad lines\")\n",
    "    except Exception as e:\n",
    "        print(f\"Method 2 failed: {e}\")\n",
    "        print(\"Unable to load captions file. Proceeding without it.\")\n",
    "        captions = None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0444a3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Après suppression des valeurs manquantes, la matrice a 4494578 lignes\n",
      "Valeur max du 1% le plus bas: 0.10910294790311445\n",
      "Valeur min du 1% le plus haut: 56.26230695693068\n",
      "Après filtrage des valeurs extrêmes, la matrice a 4269399 lignes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * Etape 2 :  Traitement des valeurs manquantes et inconsistantes\n",
    "\n",
    "def clear_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Fonction pour nettoyer la matrice en traitant les valeurs manquantes et les valeurs extrêmes.\n",
    "    \n",
    "    Args:\n",
    "        matrix (DataFrame): La matrice d'interactions à nettoyer\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: La matrice nettoyée\n",
    "    \"\"\"\n",
    "    # Traiter les valeurs manquantes\n",
    "    if matrix['timestamp'].isnull().sum() > 0:\n",
    "        # Supprimer les lignes avec timestamp manquant\n",
    "        matrix_cleaned = matrix.dropna(subset=['timestamp'])\n",
    "        print(f\"\\nAprès suppression des valeurs manquantes, la matrice a {matrix_cleaned.shape[0]} lignes\")\n",
    "    else:\n",
    "        matrix_cleaned = matrix.copy()\n",
    "    \n",
    "    # Traitement des valeurs extrêmes dans watch_ratio\n",
    "\n",
    "    #q_low representes la valeur max du 1% le plus bas\n",
    "    q_low = matrix_cleaned['watch_ratio'].quantile(0.05) # ? jouer avec ce parametre\n",
    "    print(f\"Valeur max du 1% le plus bas: {q_low}\")\n",
    "    #q_high representes la valeur min du 1% le plus haut\n",
    "    q_high = matrix_cleaned['watch_ratio'].quantile(0.9999) # ? jouer avec ce parametre\n",
    "    print(f\"Valeur min du 1% le plus haut: {q_high}\")\n",
    "\n",
    "    # Filtrer les valeurs extrêmes\n",
    "    matrix_filtered = matrix_cleaned[(matrix_cleaned['watch_ratio'] >= q_low) & \n",
    "                                    (matrix_cleaned['watch_ratio'] <= q_high)]\n",
    "    print(f\"Après filtrage des valeurs extrêmes, la matrice a {matrix_filtered.shape[0]} lignes\")\n",
    "    \n",
    "    return matrix_filtered\n",
    "small_matrix_cleaned = clear_matrix(small_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee07aef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour convertir la string en liste d'entiers\n",
    "def parse_item_categories_feat(cat_str):\n",
    "    \"\"\"\n",
    "    Convertit la représentation textuelle des catégories en liste d'entiers\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if isinstance(cat_str, str):\n",
    "            # Supprimer les crochets et convertir en liste d'entiers\n",
    "            return [int(x) for x in cat_str.strip('[]').split(',') if x.strip()]\n",
    "        print(f\"Erreur de type pour la chaîne de catégories: {cat_str}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du parsing de la chaîne de catégories: {cat_str}, erreur: {e}\")\n",
    "        return []\n",
    "\n",
    "# Appliquer la fonction à la colonne 'feat' en créant une nouvelle colonne 'category_list'\n",
    "item_categories['category_list'] = item_categories['feat'].apply(parse_item_categories_feat)\n",
    "# Créer un dictionnaire de mapping video_id -> catégories pour un accès efficace\n",
    "video_to_categories = dict(zip(item_categories['video_id'], item_categories['category_list']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6beb8539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemple d'interactions avec catégories:\n",
      "   user_id  video_id    categories  category_count\n",
      "0       14       148  [11, 28, 19]               3\n",
      "1       14       183          [28]               1\n",
      "2       14      3649           [9]               1\n",
      "3       14      5262          [25]               1\n",
      "4       14      8234           [6]               1\n",
      "\n",
      "Nombre de vidéos sans catégorie: 0\n"
     ]
    }
   ],
   "source": [
    "def add_categories_to_interactions(interactions_df):\n",
    "    \"\"\"\n",
    "    Ajoute les catégories de vidéos aux données d'interaction\n",
    "    \"\"\"\n",
    "    # Créer une colonne de catégories en utilisant le mapping\n",
    "    interactions_df['categories'] = interactions_df['video_id'].map(video_to_categories)\n",
    "    \n",
    "    # Remplacer les valeurs NaN par des listes vides\n",
    "    interactions_df['categories'] = interactions_df['categories'].fillna('').apply(lambda x: [] if x == '' else x)\n",
    "    \n",
    "    # Calculer le nombre de catégories par vidéo\n",
    "    interactions_df['category_count'] = interactions_df['categories'].apply(len)\n",
    "    \n",
    "    return interactions_df\n",
    "\n",
    "# Fusionner les métadonnées des catégories avec le jeu de données small_matrix nettoyé\n",
    "small_matrix_with_categories = add_categories_to_interactions(small_matrix_cleaned)\n",
    "\n",
    "# Vérifier la fusion des données\n",
    "print(\"\\nExemple d'interactions avec catégories:\")\n",
    "print(small_matrix_with_categories[['user_id', 'video_id', 'categories', 'category_count']].head())\n",
    "print(f\"\\nNombre de vidéos sans catégorie: {sum(small_matrix_with_categories['category_count'] == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8156ec56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemple d'interactions avec captions:\n",
      "   user_id  video_id    categories  \\\n",
      "0       14       148  [11, 28, 19]   \n",
      "1       14       183          [28]   \n",
      "2       14      3649           [9]   \n",
      "3       14      5262          [25]   \n",
      "4       14      8234           [6]   \n",
      "\n",
      "                                             caption  \n",
      "0  美60岁奶奶与21少年一见钟情，兴奋分享初次体验，称：升华了感情！ @推广小助手(O4030...  \n",
      "1          合肥高铁南站，他带了瓶开过封的茅台被拦下，酒值4000元他舍不得扔，就一饮而尽。   \n",
      "2                     美女裤兜上插“菜刀”吓坏旁人   哦豁，拔出来才发现是手机壳  \n",
      "3    生了个洋娃娃，婆婆非要发出来给大家看看，看看有没有人点赞，一分钟催我看一下，一分钟催我看一下😂  \n",
      "4  #郝劭文 小时候火遍全国，跟释小龙一起成为一代人最喜爱的童星，长大后却没能大火，你还记得那个...  \n"
     ]
    }
   ],
   "source": [
    "# Solution alternative - nettoyer puis convertir en entiers si possible\n",
    "if captions is not None:\n",
    "    try:\n",
    "        # Fonction pour extraire seulement les chiffres\n",
    "        def extract_digits(value):\n",
    "            import re\n",
    "            digits = re.findall(r'\\d+', str(value))\n",
    "            return int(digits[0]) if digits else None\n",
    "        \n",
    "        # Appliquer la fonction\n",
    "        captions['video_id_int'] = captions['video_id'].apply(extract_digits)\n",
    "        \n",
    "        # Filtrer les lignes où la conversion a fonctionné\n",
    "        captions_valid = captions.dropna(subset=['video_id_int'])\n",
    "        \n",
    "        # Créer le dictionnaire avec les ID numériques\n",
    "        video_captions = dict(zip(captions_valid['video_id_int'], captions_valid['caption']))\n",
    "        \n",
    "        # Ajouter le texte des captions\n",
    "        small_matrix_with_categories['caption'] = small_matrix_with_categories['video_id'].map(video_captions)\n",
    "\n",
    "        print(\"\\nExemple d'interactions avec captions:\")\n",
    "        print(small_matrix_with_categories[['user_id', 'video_id', 'categories', 'caption']].head())\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'ajout des captions: {e}\")\n",
    "        print(\"Poursuite du traitement sans les données de captions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "accda7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemple d'interactions avec métadonnées agrégées:\n",
      "   user_id  video_id    categories  total_likes  avg_daily_likes  \\\n",
      "0       14       148  [11, 28, 19]        31199       495.222222   \n",
      "1       14       183          [28]       210670      3343.968254   \n",
      "2       14      3649           [9]       279456      4435.809524   \n",
      "3       14      5262          [25]      1363469     21642.365079   \n",
      "4       14      8234           [6]        87997      1396.777778   \n",
      "\n",
      "   total_comments  avg_daily_comments  \n",
      "0            4574           72.603175  \n",
      "1            5684           90.222222  \n",
      "2            5900           93.650794  \n",
      "3           29188          463.301587  \n",
      "4            4328           68.698413  \n"
     ]
    }
   ],
   "source": [
    "# Vérifier si item_features est disponible\n",
    "if 'item_features' in locals() and not item_features.empty:\n",
    "    # Convertir date en datetime si nécessaire\n",
    "    if not pd.api.types.is_datetime64_any_dtype(item_features['date']):\n",
    "        item_features['date'] = pd.to_datetime(item_features['date'], format='%Y%m%d', errors='coerce')\n",
    "    \n",
    "    # Sélectionner les colonnes d'intérêt\n",
    "    selected_features = ['video_id', 'date', 'play_progress', \n",
    "                         'like_cnt', 'comment_cnt', 'share_cnt']\n",
    "    \n",
    "    # Créer des agrégations pertinentes pour des compteurs quotidiens\n",
    "    video_features_agg = item_features[selected_features].groupby('video_id').agg({\n",
    "        'date': 'max',                    # Date la plus récente pour référence\n",
    "        'play_progress': 'mean',          # Progression moyenne sur toute la période\n",
    "        'like_cnt': 'sum',                # Total des likes sur toute la période\n",
    "        'comment_cnt': 'sum',             # Total des commentaires sur toute la période\n",
    "        'share_cnt': 'sum'                # Total des partages sur toute la période\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Calculer le nombre de jours avec des données pour chaque vidéo\n",
    "    days_per_video = item_features.groupby('video_id')['date'].nunique()\n",
    "    video_features_agg['days_tracked'] = video_features_agg['video_id'].map(days_per_video)\n",
    "    \n",
    "    # Calculer les moyennes quotidiennes\n",
    "    video_features_agg['avg_daily_likes'] = video_features_agg['like_cnt'] / video_features_agg['days_tracked']\n",
    "    video_features_agg['avg_daily_comments'] = video_features_agg['comment_cnt'] / video_features_agg['days_tracked']\n",
    "    video_features_agg['avg_daily_shares'] = video_features_agg['share_cnt'] / video_features_agg['days_tracked']\n",
    "    \n",
    "    # Renommer les colonnes pour refléter l'agrégation\n",
    "    video_features_agg = video_features_agg.rename(columns={\n",
    "        'play_progress': 'avg_play_progress',\n",
    "        'like_cnt': 'total_likes',\n",
    "        'comment_cnt': 'total_comments',\n",
    "        'share_cnt': 'total_shares'\n",
    "    })\n",
    "    \n",
    "    # Fusionner avec notre dataset\n",
    "    small_matrix_with_metadata = pd.merge(\n",
    "        small_matrix_with_categories,\n",
    "        video_features_agg,\n",
    "        on='video_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_features')\n",
    "    )\n",
    "    \n",
    "    # Afficher un exemple du résultat\n",
    "    print(\"\\nExemple d'interactions avec métadonnées agrégées:\")\n",
    "    print(small_matrix_with_metadata[['user_id', 'video_id', 'categories', \n",
    "                                     'total_likes', 'avg_daily_likes', \n",
    "                                     'total_comments', 'avg_daily_comments']].head())\n",
    "else:\n",
    "    small_matrix_with_metadata = small_matrix_with_categories\n",
    "# suppression de la colonne 'date' et 'timestamp' car elles ne sont plus nécessaires\n",
    "small_matrix_with_metadata.drop(columns=['date', 'timestamp'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8800dcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensions finales du dataset fusionné: (4269399, 18)\n",
      "Nombre de colonnes après fusion: 18\n",
      "Colonnes disponibles après fusion:\n",
      "['user_id', 'video_id', 'play_duration', 'video_duration', 'time', 'watch_ratio', 'categories', 'category_count', 'caption', 'date_features', 'avg_play_progress', 'total_likes', 'total_comments', 'total_shares', 'days_tracked', 'avg_daily_likes', 'avg_daily_comments', 'avg_daily_shares']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# * Récapitulatif des données fusionnées\n",
    "print(f\"\\nDimensions finales du dataset fusionné: {small_matrix_with_metadata.shape}\")\n",
    "print(f\"Nombre de colonnes après fusion: {len(small_matrix_with_metadata.columns)}\")\n",
    "print(\"Colonnes disponibles après fusion:\")\n",
    "print(small_matrix_with_metadata.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c15939c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         user_id  video_id  play_duration  video_duration  \\\n",
      "0             14       148           4381            6067   \n",
      "1             14       183          11635            6100   \n",
      "2             14      3649          22422           10867   \n",
      "3             14      5262           4479            7908   \n",
      "4             14      8234           4602           11000   \n",
      "...          ...       ...            ...             ...   \n",
      "4269394     7162      9177           5315           37205   \n",
      "4269395     7162      4987          10085            8167   \n",
      "4269396     7162      7988          50523           49319   \n",
      "4269397     7162      6533           2190            8000   \n",
      "4269398     7162      6523          11909            7255   \n",
      "\n",
      "                            time  watch_ratio    categories  category_count  \\\n",
      "0        2020-07-05 05:27:48.378     0.722103  [11, 28, 19]               3   \n",
      "1        2020-07-05 05:28:00.057     1.907377          [28]               1   \n",
      "2        2020-07-05 05:29:09.479     2.063311           [9]               1   \n",
      "3        2020-07-05 05:30:43.285     0.566388          [25]               1   \n",
      "4        2020-07-05 05:35:43.459     0.418364           [6]               1   \n",
      "...                          ...          ...           ...             ...   \n",
      "4269394  2020-09-01 20:06:35.984     0.142857          [16]               1   \n",
      "4269395  2020-09-02 14:44:51.342     1.234848          [28]               1   \n",
      "4269396  2020-09-03 08:45:01.474     1.024412          [16]               1   \n",
      "4269397  2020-09-04 22:56:32.021     0.273750          [28]               1   \n",
      "4269398  2020-09-05 00:32:09.154     1.641489      [25, 28]               2   \n",
      "\n",
      "                                                   caption date_features  \\\n",
      "0        美60岁奶奶与21少年一见钟情，兴奋分享初次体验，称：升华了感情！ @推广小助手(O4030...    2020-09-05   \n",
      "1                合肥高铁南站，他带了瓶开过封的茅台被拦下，酒值4000元他舍不得扔，就一饮而尽。     2020-09-05   \n",
      "2                           美女裤兜上插“菜刀”吓坏旁人   哦豁，拔出来才发现是手机壳    2020-09-05   \n",
      "3          生了个洋娃娃，婆婆非要发出来给大家看看，看看有没有人点赞，一分钟催我看一下，一分钟催我看一下😂    2020-09-05   \n",
      "4        #郝劭文 小时候火遍全国，跟释小龙一起成为一代人最喜爱的童星，长大后却没能大火，你还记得那个...    2020-09-05   \n",
      "...                                                    ...           ...   \n",
      "4269394                        教你一个小方法，#美白  又#去皱 #健康科普在快手     2020-09-05   \n",
      "4269395           辽宁大量特警突袭一药店，多人蒙头套被押！目击者：该药店开业才几个月，看起来很普通    2020-09-05   \n",
      "4269396                肝不好的5大表现#中医养生 #养生 #健康养生 #中医 #中医·中药     2020-09-05   \n",
      "4269397                                 心疼！两岁失明癌症宝宝舀不到饭被急哭    2020-09-05   \n",
      "4269398                                     这娃状态有点迷 #家有萌宝     2020-09-05   \n",
      "\n",
      "         avg_play_progress  total_likes  total_comments  total_shares  \\\n",
      "0                 0.710828        31199            4574           577   \n",
      "1                 0.484098       210670            5684          1496   \n",
      "2                 0.681001       279456            5900          8383   \n",
      "3                 0.654183      1363469           29188          8583   \n",
      "4                 0.490624        87997            4328           181   \n",
      "...                    ...          ...             ...           ...   \n",
      "4269394           0.408722       600659            8454        307610   \n",
      "4269395           0.745295       321362            9760          3328   \n",
      "4269396           0.308004       180663            1473        118171   \n",
      "4269397           0.761755       683737           56849          3116   \n",
      "4269398           0.761855       349553           11081         14240   \n",
      "\n",
      "         days_tracked  avg_daily_likes  avg_daily_comments  avg_daily_shares  \n",
      "0                  63       495.222222           72.603175          9.158730  \n",
      "1                  63      3343.968254           90.222222         23.746032  \n",
      "2                  63      4435.809524           93.650794        133.063492  \n",
      "3                  63     21642.365079          463.301587        136.238095  \n",
      "4                  63      1396.777778           68.698413          2.873016  \n",
      "...               ...              ...                 ...               ...  \n",
      "4269394            13     46204.538462          650.307692      23662.307692  \n",
      "4269395             5     64272.400000         1952.000000        665.600000  \n",
      "4269396             4     45165.750000          368.250000      29542.750000  \n",
      "4269397             4    170934.250000        14212.250000        779.000000  \n",
      "4269398             4     87388.250000         2770.250000       3560.000000  \n",
      "\n",
      "[4269399 rows x 18 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['small_matrix_with_metadata.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(small_matrix_with_metadata)\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Sauvegarde\n",
    "joblib.dump(small_matrix_with_metadata, 'small_matrix_with_metadata.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recosys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
